{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab53e2f-8004-49c9-8c8c-7748022f48ca",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install ms-fabric-cli --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181ec38-733e-45da-bfed-1b7fa7f44f56",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# First Time Setup\n",
    "If it´s the first time running the script, set the parameter 'FIRST_RUN' as 'True', else set it up as 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b42300-bc68-44ca-9606-09745af13378",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "FIRST_RUN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93e835-7fed-4990-a333-a95ea976a78a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Variables\n",
    "\n",
    "Set the following variables for the initial setup or update of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a936d-19d8-4bbd-8e42-f5a971bc3adc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Key Vault URI\n",
    "key_vault_uri = f\"\"\n",
    "\n",
    "# Key Vault secret name with the tenant id\n",
    "key_vault_tenant_id = f\"tenant-id\"\n",
    "\n",
    "# Key vault secret name with the App Id of the Service Principal\n",
    "key_vault_client_id = f\"fabric-admin-api-sp-id\"\n",
    "\n",
    "# Key vault secret name with the secret of the Service Principal\n",
    "key_vault_client_secret = f\"fabric-admin-api-sp-secret\"\n",
    "\n",
    "# Id of the Security Group with the Service Principal used for the Admin API´s and Gateway Administration\n",
    "group_id = f\"\"\n",
    "\n",
    "# Capacity ID of the capacity you want to setup. You can change it manually later in the Eventstream, \n",
    "# or add more capacities\n",
    "capacity_id = f\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8afe6c1-c599-47f3-ae77-53e975811e4e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Don´t change the following variables unless specified by the repo owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860d419-91c1-4840-9d3d-7a516750271d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "##### DO NET CHANGE UNLESS SPECIFIED OTHERWISE ####\n",
    "repo_owner = \"ecotte\"\n",
    "repo_name = \"Fabric-Monitoring-RTI\"\n",
    "branch = \"Capacity\"\n",
    "folder_prefix = \"\"\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37310857-6b85-4063-a1cf-0905e91d1faf",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af11a20-a1fa-46f5-a2f1-59667ccc6b2d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "from zipfile import ZipFile \n",
    "import shutil\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import yaml\n",
    "import sempy.fabric as fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d04fe-3bb9-49ce-bcd5-00c41ea09405",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Download of source & config files\n",
    "This part downloads all source and config files of FUAM needed for the deployment into the ressources of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96bdf-adaf-4501-a631-a51612653c8b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "def download_folder_as_zip(repo_owner, repo_name, output_zip, branch=\"main\", folder_to_extract=\"src\",  remove_folder_prefix = \"\"):\n",
    "    # Construct the URL for the GitHub API to download the repository as a zip file\n",
    "    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/zipball/{branch}\"\n",
    "    \n",
    "    # Make a request to the GitHub API\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Ensure the directory for the output zip file exists\n",
    "    os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n",
    "    \n",
    "    # Create a zip file in memory\n",
    "    with zipfile.ZipFile(BytesIO(response.content)) as zipf:\n",
    "        with zipfile.ZipFile(output_zip, 'w') as output_zipf:\n",
    "            for file_info in zipf.infolist():\n",
    "                parts = file_info.filename.split('/')\n",
    "                if  re.sub(r'^.*?/', '/', file_info.filename).startswith(folder_to_extract): \n",
    "                    # Extract only the specified folder\n",
    "                    file_data = zipf.read(file_info.filename)                    \n",
    "                    output_zipf.writestr(('/'.join(parts[1:]).replace(remove_folder_prefix, \"\")), file_data)\n",
    "\n",
    "def uncompress_zip_to_folder(zip_path, extract_to):\n",
    "    # Ensure the directory for extraction exists\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    # Uncompress all files from the zip into the specified folder\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    # Delete the original zip file\n",
    "    os.remove(zip_path)\n",
    "\n",
    "\n",
    "download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/src/src.zip\", branch = branch, folder_to_extract= f\"{folder_prefix}/src\", remove_folder_prefix = f\"{folder_prefix}\")\n",
    "download_folder_as_zip(repo_owner, repo_name, output_zip = \"./builtin/config/config.zip\", branch = branch, folder_to_extract= f\"{folder_prefix}/config\" , remove_folder_prefix = f\"{folder_prefix}\")\n",
    "uncompress_zip_to_folder(zip_path = \"./builtin/config/config.zip\", extract_to= \"./builtin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96e880-7c1b-4ed5-9ea9-eb4055d41537",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Definition of deployment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5a660-9826-4865-ac50-ddf8ce578148",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "def run_fab_command( command, capture_output: bool = False, silently_continue: bool = False):\n",
    "    result = subprocess.run([\"fab\", \"-c\", command], capture_output=capture_output, text=True)\n",
    "    if (not(silently_continue) and (result.returncode > 0 or result.stderr)):\n",
    "       raise Exception(f\"Error running fab command. exit_code: '{result.returncode}'; stderr: '{result}'\")    \n",
    "    if (capture_output): \n",
    "        output = result.stdout.strip()\n",
    "        return output\n",
    "\n",
    "def fab_get_id(name):\n",
    "    id = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q id\" , capture_output = True, silently_continue= True)\n",
    "    return(id)\n",
    "\n",
    "def fab_get_item(name):\n",
    "    item = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name}\" , capture_output = True, silently_continue= True)\n",
    "    return(item)\n",
    "\n",
    "def fab_get_display_name(name):\n",
    "    display_name = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q displayName\" , capture_output = True, silently_continue= True)\n",
    "    return(display_name)\n",
    "\n",
    "def fab_get_kusto_query_uri(name):\n",
    "    connection = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q properties.queryServiceUri\", capture_output = True, silently_continue= True)\n",
    "    return(connection)\n",
    "\n",
    "def fab_get_kusto_ingest_uri(name):\n",
    "    connection = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q properties.ingestionServiceUri\", capture_output = True, silently_continue= True)\n",
    "    return(connection)\n",
    "\n",
    "def fab_get_folders():\n",
    "    response = run_fab_command(f\"api workspaces/{trg_workspace_id}/folders\", capture_output = True, silently_continue= True)\n",
    "    return(json.loads(response).get('text',{}).get('value',[]))\n",
    "\n",
    "def fab_get_folder(folder_name):\n",
    "    for f in fab_get_folders():\n",
    "        if f.get('displayName') == folder_name:\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def fab_assign_item_folder(name,folder):\n",
    "    folder_details = fab_get_folder(folder)\n",
    "    item_id = fab_get_id(name)\n",
    "\n",
    "    if folder_details is None:\n",
    "        payload = json.dumps({\"displayName\": folder})\n",
    "        folder_details = run_fab_command(f\"api -X post workspaces/{trg_workspace_id}/folders -i {payload}\", capture_output = True, silently_continue= True)\n",
    "        folder_details = json.loads(folder_details).get('text',{})\n",
    "\n",
    "    payload = json.dumps({\"folder\": folder_details.get('id')})\n",
    "\n",
    "    return run_fab_command(f\"api -X patch workspaces/{trg_workspace_id}/items/{item_id} -i {payload}\", capture_output = True, silently_continue= True)\n",
    "\n",
    "def get_id_by_name(name):\n",
    "    for it in deployment_order:\n",
    "        if it.get(\"name\") == name:\n",
    "                return it.get(\"id\")\n",
    "    return None\n",
    "\n",
    "def get_schedule_by_name(name):\n",
    "    for it in deployment_order:\n",
    "        if it.get(\"name\") == name:\n",
    "                return it.get(\"schedule\")\n",
    "    return None\n",
    "\n",
    "def add_schedule(name):\n",
    "    item = run_fab_command(f\"get /{trg_workspace_name}.Workspace/{name} -q schedules\" , capture_output = True, silently_continue= True)\n",
    "\n",
    "    if len(json.loads(item)) == 0:\n",
    "        schedule = get_schedule_by_name(name)\n",
    "\n",
    "        return run_fab_command(f\"job run-sch /{trg_workspace_name}.Workspace/{name} -i {json.dumps(schedule)}\" , capture_output = True, silently_continue=True)\n",
    "\n",
    "    return f\"\"\"Job schedule for '{name}' already exists...\n",
    "* Job schedule {item}\"\"\" \n",
    "\n",
    "def copy_to_tmp(name):\n",
    "    shutil.rmtree(\"./builtin/tmp\",  ignore_errors=True)\n",
    "    path2zip = \"./builtin/src/src.zip\"\n",
    "    with  ZipFile(path2zip) as archive:\n",
    "        for file in archive.namelist():\n",
    "            if file.startswith(f'src/{name}/'):\n",
    "                archive.extract(file, './builtin/tmp')\n",
    "    return(f\"./builtin/tmp/src/{name}\" )\n",
    "\n",
    "def replace_ids_in_folder(folder_path, mapping_table):\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(('.py', '.json', '.pbir', '.platform', '.ipynb', '.tmdl')) and not file_name.endswith('report.json'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    for mapping in mapping_table:  \n",
    "                        content = content.replace(mapping[\"old_id\"], mapping[\"new_id\"])\n",
    "                with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                    file.write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807fcaf-3b97-4952-a720-a55f75dab7a0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## CLI SPN Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b689de-95e4-47f1-b6cd-78c0324acb06",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Set environment parameters for Fabric CLI\n",
    "token = notebookutils.credentials.getToken('pbi')\n",
    "client_id = notebookutils.credentials.getSecret(key_vault_uri, key_vault_client_id)\n",
    "client_secret = notebookutils.credentials.getSecret(key_vault_uri, key_vault_client_secret)\n",
    "tenant_id = notebookutils.credentials.getSecret(key_vault_uri, key_vault_tenant_id)\n",
    "\n",
    "os.environ['FAB_TOKEN_AZURE'] = token\n",
    "\n",
    "run_fab_command(f\"config set encryption_fallback_enabled true\" , capture_output = True, silently_continue= True)\n",
    "\n",
    "run_fab_command(f\"auth login -u {client_id} -p {client_secret} --tenant {tenant_id}\" , capture_output = False, silently_continue= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa08bf-f156-4110-941c-2325a2a6120c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get current Workspace\n",
    "This cell gets the current workspace to deploy FUAM automatically inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fee19-3f2f-4411-8188-19d14071c536",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "base_path = './builtin/'\n",
    "config_path = os.path.join(base_path, 'config/item_config.yaml')\n",
    "\n",
    "with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "deploy_order_path = os.path.join(base_path, 'config/deployment_order.json')\n",
    "with open(deploy_order_path, 'r') as file:\n",
    "        deployment_order = json.load(file)\n",
    "\n",
    "src_workspace_name = config.get('workspace',{}).get('src')\n",
    "src_capacity_name = config.get('capacity',{}).get('name')\n",
    "\n",
    "semantic_model_connect_to_lakehouse = config.get('fuam_lakehouse_semantic_models',{})\n",
    "\n",
    "mapping_table=[]\n",
    "\n",
    "trg_workspace_id = fabric.get_notebook_workspace_id()\n",
    "res = run_fab_command(f\"api -X get workspaces/{trg_workspace_id}\" , capture_output = True, silently_continue=True)\n",
    "trg_workspace_name = json.loads(res)[\"text\"][\"displayName\"]\n",
    "\n",
    "print(f\"Current workspace: {trg_workspace_name}\")\n",
    "print(f\"Current workspace ID: {trg_workspace_id}\")\n",
    "\n",
    "\n",
    "mapping_table.append({ \"old_id\": get_id_by_name(src_capacity_name), \"new_id\": capacity_id })\n",
    "mapping_table.append({ \"old_id\": get_id_by_name(src_workspace_name), \"new_id\": trg_workspace_id })\n",
    "mapping_table.append({ \"old_id\": \"00000000-0000-0000-0000-000000000000\", \"new_id\": trg_workspace_id })\n",
    "mapping_table.append({ \"old_id\": \"{key_vault_uri}\", \"new_id\": key_vault_uri })\n",
    "mapping_table.append({ \"old_id\": \"{key_vault_tenant_id}\", \"new_id\": key_vault_tenant_id })\n",
    "mapping_table.append({ \"old_id\": \"{key_vault_client_id}\", \"new_id\": key_vault_client_id })\n",
    "mapping_table.append({ \"old_id\": \"{key_vault_client_secret}\", \"new_id\": key_vault_client_secret })\n",
    "\n",
    "display(mapping_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b073ab-78fd-44fe-8380-f3b3d2fda71e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Add Group as contributor in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e62e74-18f1-4b3a-afef-41932aca14d8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    payload = json.dumps({\n",
    "                \"principal\": {\n",
    "                    \"id\": group_id,\n",
    "                    \"type\": \"Group\",\n",
    "                    \"groupDetails\": {\n",
    "                        \"groupType\": \"SecurityGroup\",\n",
    "                    }\n",
    "                },\n",
    "                \"role\": \"Admin\",\n",
    "            })\n",
    "\n",
    "    result = run_fab_command(f\"api -X post workspaces/{trg_workspace_id}/roleAssignments -i {payload}\" , capture_output = True, silently_continue= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c66dd-47bb-4394-a8b7-3772af6dd0ef",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deployment Logic\n",
    "This part iterates through all the items, gets the respective source code, replaces all IDs dynamically and deploys the new item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eaaac6-14e5-47c8-99f2-66bcdb308e00",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "exclude = [src_workspace_name,src_capacity_name]\n",
    "\n",
    "for it in deployment_order:\n",
    "\n",
    "    new_id = None\n",
    "    \n",
    "    name = it[\"name\"]\n",
    "\n",
    "    if name in exclude:\n",
    "        continue\n",
    "\n",
    "    if not FIRST_RUN and \".Eventstream\" in name:\n",
    "        continue\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"#############################################\")\n",
    "    print(f\"Deploying {name}\")\n",
    "\n",
    "    # Copy and replace IDs in the item\n",
    "    tmp_path = copy_to_tmp(name)\n",
    "\n",
    "    cli_parameter = ''\n",
    "    if \".Notebook\" in name:\n",
    "        cli_parameter = cli_parameter + \" --format .py\"\n",
    "\n",
    "    replace_ids_in_folder(tmp_path, mapping_table)    \n",
    "    \n",
    "    run_fab_command(f\"import  /{trg_workspace_name}.Workspace/{name} -i {tmp_path} -f {cli_parameter} \", silently_continue= True)\n",
    "    new_id= fab_get_id(name)\n",
    "\n",
    "    if \".KQLDatabase\" in name:\n",
    "        display_name = fab_get_display_name(name)\n",
    "        mapping_table.append({ \"old_id\": \"{kusto_db_name}\", \"new_id\": display_name })\n",
    "    elif \".Eventhouse\" in name:\n",
    "        query_uri = fab_get_kusto_query_uri(name)\n",
    "        mapping_table.append({ \"old_id\": \"{kusto_query_uri}\", \"new_id\": query_uri })\n",
    "        ingest_uri = fab_get_kusto_ingest_uri(name)\n",
    "        mapping_table.append({ \"old_id\": \"{kusto_ingest_uri}\", \"new_id\": ingest_uri })\n",
    "    mapping_table.append({ \"old_id\": it[\"id\"], \"new_id\": new_id })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2249c-7e39-40e5-b791-d0266b14ea18",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Logout Service Principal\n",
    "Currently the creation of job schedules doesn´t support SPN, so we need to do it with the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579ac2b-1ca0-4243-b80d-149c0eed9de8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "run_fab_command(f\"auth logout\", capture_output = True, silently_continue=False)\n",
    "run_fab_command(f\"config set encryption_fallback_enabled false\" , capture_output = True, silently_continue= True)\n",
    "\n",
    "token = notebookutils.credentials.getToken('pbi')\n",
    "os.environ['FAB_TOKEN'] = token\n",
    "os.environ['FAB_TOKEN_ONELAKE'] = token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c067f44-ca64-49cb-b47b-985930158415",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create Notebooks Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2e544-0d0d-4d3f-a9b9-e03f107ce768",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for it in deployment_order:\n",
    "    name = it[\"name\"]\n",
    "    if \".Notebook\" in name:\n",
    "        schedule = add_schedule(name)\n",
    "\n",
    "        print(schedule)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
