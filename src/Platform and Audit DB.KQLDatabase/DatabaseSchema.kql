// KQL script
// Use management commands in this script to configure your database items, such as tables, functions, materialized views, and more.


.create-merge table ActivityEventsRaw (ActivityEvents:dynamic) with (folder = "Platform/History/Events") 
.create-merge table ActivityEvents (Id:guid, Workload:string, RecordType:int, RequestId:guid, RefreshEnforcementPolicy:int, CreationTime:datetime, Activity:string, Operation:string, OrganizationId:guid, UserId:string, UserKey:string, UserType:int, details:dynamic) with (folder = "Platform/Events") 
.create-merge table DatasourceInstancesHistory (DatasourceInstances:dynamic, scanTime:datetime, misconfigured:bool) with (folder = "Platform/History/Inventory") 
.create-merge table DatasourceInstance (gatewayId:guid, datasourceId:guid, scanTime:datetime, datasourceType:string, connectionDetails:dynamic, misconfigured:bool) with (folder = "Platform/Inventory") 
.create-merge table TenantSettingsHistory (SettingName:string, Title:string, Enabled:bool, CanSpecifySecurityGroups:bool, TenantSettingGroup:string, EnabledSecurityGroups:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table TenantSettings (SettingName:string, Title:string, Enabled:bool, CanSpecifySecurityGroups:bool, TenantSettingGroup:string, EnabledSecurityGroups:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table CapacitiesHistory (CapacityId:guid, CapacityName:string, Sku:string, Region:string, State:string, Admins:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table Capacities (CapacityId:guid, CapacityName:string, Sku:string, Region:string, State:string, Admins:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table DomainsHistory (DomainID:guid, DomainName:string, Description:string, ParentDomainID:string, ContributorsScope:string, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table Domains (DomainID:guid, DomainName:string, Description:string, ParentDomainID:string, ContributorsScope:string, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table WorkspacesHistory (id:guid, name:string, description:string, domainId:guid, state:string, type:string, defaultDatasetStorageFormat:string, isOnDedicatedCapacity:bool, capacityId:guid, dataRetrievalState:string, details:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table WorkspacesUsersHistory (workspaceId:guid, workspaceName:string, graphId:guid, displayName:string, emailAddress:string, identifier:dynamic, principalType:string, userType:string, groupUserAccessRight:string, details:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table ItemsUsersHistory (workspaceId:guid, workspaceName:string, itemType:string, itemId:guid, itemName:string, graphId:guid, displayName:string, emailAddress:string, identifier:string, principalType:string, userType:string, userAccessRight:string, details:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table Workspaces (id:guid, name:string, description:string, domainId:guid, state:string, type:string, defaultDatasetStorageFormat:string, isOnDedicatedCapacity:bool, capacityId:guid, dataRetrievalState:string, details:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table ItemsHistory (workspaceId:guid, workspaceName:string, itemType:string, itemId:guid, itemName:string, details:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table Items (workspaceId:guid, workspaceName:string, itemType:string, itemId:guid, itemName:string, details:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table WorkspacesUsers (workspaceId:guid, workspaceName:string, graphId:guid, displayName:string, emailAddress:string, identifier:dynamic, principalType:string, userType:string, groupUserAccessRight:string, details:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table ItemsUsers (workspaceId:guid, workspaceName:string, itemType:string, itemId:guid, itemName:string, graphId:guid, displayName:string, emailAddress:string, identifier:string, principalType:string, userType:string, userAccessRight:string, details:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table CapacityDelegatedSettings (CapacityId:guid, SettingName:string, SettingTitle:string, SettingEnabled:bool, CanSpecifySecurityGroups:bool, EnabledSecurityGroups:dynamic, TenantSettingGroup:string, TenantSettingProperties:dynamic, DelegateToWorkspace:bool, DelegatedFrom:string, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table CapacityDelegatedSettingsHistory (CapacityId:guid, SettingName:string, SettingTitle:string, SettingEnabled:bool, CanSpecifySecurityGroups:bool, EnabledSecurityGroups:dynamic, TenantSettingGroup:string, TenantSettingProperties:dynamic, DelegateToWorkspace:bool, DelegatedFrom:string, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table GatewaysHistory (gatewayName:string, gatewayId:guid, type:string, publicKeyExponent:string, publicKeyModulus:string, version:string, numberOfMemebers:int, loadBalancingSetting:string, allowCloudConnectionRefresh:bool, allowCustomConnectors:bool, scanTime:datetime) with (folder = "Gateway/Raw") 
.create-merge table Gateways (gatewayName:string, gatewayId:guid, type:string, publicKeyExponent:string, publicKeyModulus:string, version:string, numberOfMemebers:int, loadBalancingSetting:string, allowCloudConnectionRefresh:bool, allowCustomConnectors:bool, scanTime:datetime) with (folder = "Gateway/Inventory") 
.create-merge table GatewayMembers (gatewayId:guid, memberId:guid, memberName:string, publicKeyExponent:string, publicKeyModulus:string, version:string, memberEnabled:bool, scanTime:datetime) with (folder = "Gateway/Inventory") 
.create-merge table GatewayMembersHistory (gatewayId:guid, memberId:guid, memberName:string, publicKeyExponent:string, publicKeyModulus:string, version:string, memberEnabled:bool, scanTime:datetime) with (folder = "Gateway/Raw") 
.create-merge table ConnectionsHistory (connectionId:guid, connectionName:string, gatewayId:guid, connectivityType:string, connectionPath:string, connectionType:string, privacyLevel:string, credentialType:string, singleSignOnType:string, connectionEncryption:string, skipTestConnection:bool, scanTime:datetime) with (folder = "Gateway/Raw") 
.create-merge table Connections (connectionId:guid, connectionName:string, gatewayId:guid, connectivityType:string, connectionPath:string, connectionType:string, privacyLevel:string, credentialType:string, singleSignOnType:string, connectionEncryption:string, skipTestConnection:bool, scanTime:datetime) with (folder = "Gateway/Inventory") 
.create-merge table GatewaysHeartbeat (GatewayId:guid, FileVersion:string, ServerTimestampUTC:datetime, Responding:bool, ProcessName:string, ProductVersion:string, StartTime:datetime) with (folder = "Gateway/System") 
.create-or-alter table GatewaysHeartbeat ingestion json mapping 'GatewaysHeartbeat_mapping'
```
[{"Properties":{"Path":"$['GatewayId']"},"column":"GatewayId","datatype":""},{"Properties":{"Path":"$['FileVersion']"},"column":"FileVersion","datatype":""},{"Properties":{"Path":"$['ServerTimestampUTC']"},"column":"ServerTimestampUTC","datatype":""},{"Properties":{"Path":"$['Responding']"},"column":"Responding","datatype":""},{"Properties":{"Path":"$['ProcessName']"},"column":"ProcessName","datatype":""},{"Properties":{"Path":"$['ProductVersion']"},"column":"ProductVersion","datatype":""},{"Properties":{"Path":"$['StartTime']"},"column":"StartTime","datatype":""}]
```
.create-merge table ['GatewayReports-Raw'] (logType:string, log:dynamic, logDate:datetime) with (folder = "Gateway/Raw") 
.create-or-alter table ['GatewayReports-Raw'] ingestion json mapping 'GatewayReports-Raw_mapping'
```
[{"Properties":{"Path":"$['logType']"},"column":"logType","datatype":""},{"Properties":{"Path":"$['log']"},"column":"log","datatype":""},{"Properties":{"Path":"$['logDate']"},"column":"logDate","datatype":""}]
```
.create-merge table SystemCounterAggregationReport (GatewayObjectId:guid, AggregationStartTimeUTC:datetime, AggregationEndTimeUTC:datetime, CounterName:string, Max:real, Min:real, Average:real) with (folder = "Gateway/System") 
.create-merge table QueryStartReport (GatewayObjectId:guid, RequestId:guid, DataSource:dynamic, QueryTrackingId:guid, QueryExecutionStartTimeUTC:datetime, OperationType:string, QueryText:string, Table:string, EvaluationContext:dynamic, ServiceName:string, CurrentActivityId:guid, ItemId:guid, QueryType:string, RootActivityId:guid, SKU:string, WorkspaceId:guid, HostContextType:string, ConnectionIds:string) with (folder = "Gateway/Reports") 
.create-merge table QueryExecutionReport (GatewayObjectId:guid, RequestId:guid, DataSource:dynamic, QueryTrackingId:guid, QueryExecutionEndTimeUTC:datetime, QueryExecutionDuration_ms_:long, QueryType:string, DataReadingAndSerializationDuration_ms_:long, SpoolingDiskWritingDuration_ms_:long, SpoolingDiskReadingDuration_ms_:long, SpoolingTotalDataSize_byte_:long, DataProcessingEndTimeUTC:datetime, DataProcessingDuration_ms_:long, Success:string, ErrorMessage:string) with (folder = "Gateway/Reports") 
.create-merge table OpenConnectionReport (GatewayObjectId:guid, RequestId:guid, DataSource:dynamic, OpenConnectionStartTimeUTC:datetime, OpenConnectionTrackingId:guid, ProviderName:string, OpenConnectionDuration_ms_:long, Success:string, ErrorMessage:string) with (folder = "Gateway/Reports") 
.create-merge table QueryExecutionAggregationReport (GatewayObjectId:guid, AggregationStartTimeUTC:datetime, AggregationEndTimeUTC:datetime, DataSource:dynamic, Success:string, AverageQueryExecutionDuration_ms_:real, MaxQueryExecutionDuration_ms_:long, MinQueryExecutionDuration_ms_:long, QueryType:string, AverageDataProcessingDuration_ms_:real, MaxDataProcessingDuration_ms_:long, MinDataProcessingDuration_ms_:long, Count:long) with (folder = "Gateway/Reports") 
.create-merge table QueryStreamingReport (GatewayObjectId:guid, RequestId:guid, DataSource:dynamic, QueryTrackingId:guid, StreamingStartTimeUTC:datetime, SpoolingDiskReadingDuration_ms_:long, StreamingDuration_ms_:long, Success:string, ErrorMessage:string) with (folder = "Gateway/Reports") 
.create-merge table MashupEvaluationReport (GatewayObjectId:guid, QueryTrackingId:guid, ConnectionId:guid, DataSourceKinds:string, DataSourcePaths:string, EndTimeUTC:datetime, ['AverageCommit byte']:real, AverageIODataBytesPerSecond:real, AveragePercentProcessorTime:real, ['AverageWorkingSet byte']:real, ['MaxCommit byte']:long, MaxIODataBytesPerSecond:long, MaxPercentProcessorTime:real, ['MaxWorkingSet byte']:long, TotalBytes:long, TotalProcessorTime:timespan, TotalRows:real) with (folder = "Gateway/Reports") 
.create-merge table ConcurrentOperationAggregationReport (GatewayObjectId:guid, AggregationStartTimeUTC:datetime, AggregationEndTimeUTC:datetime, CounterName:string, Max:real, Min:real, Average:real) with (folder = "Gateway/Reports") 
.create-merge table GatewayNodeInfoRaw (clusterId:guid, clusterName:string, nodeId:guid, machine:string, cloudDatasourceRefresh:bool, contactInformation:string, customConnectors:bool, status:string, type:string, version:string, versionStatus:string, osName:string, osVersion:string, cores:long, logicalCores:long, memoryGb:real, logDate:datetime) with (folder = "Gateway/Raw") 
.create-merge table CopyExecutionReport (GatewayObjectId:guid, ActivityId:guid, CopyExecutionStartTimeUTC:datetime, CompletionStatus:string, CopyExecutionDuration_ms:decimal, CopyWorkerCPUUtilizationPercentage:decimal, CopyWorkerMemoryUsage_byte:decimal) with (folder = "Gateway/Reports") 
.create-merge table SemanticModelDetailsHistory (workspaceId:guid, workspaceName:string, itemType:string, itemId:guid, itemName:string, tables:dynamic, relationships:dynamic, expressions:dynamic, roles:dynamic, upstreamDataflows:dynamic, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table SemanticModelDetails (workspaceId:guid, workspaceName:string, itemType:string, itemId:guid, itemName:string, tables:dynamic, relationships:dynamic, expressions:dynamic, roles:dynamic, upstreamDataflows:dynamic, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table DomainDelegatedSettingsHistory (DomainId:guid, SettingName:string, Title:string, Enabled:bool, CanSpecifySecurityGroups:bool, EnabledSecurityGroups:dynamic, TenantSettingGroup:string, DelegatedToWorkspace:bool, DelegatedFrom:string, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table DomainDelegatedSettings (DomainId:guid, SettingName:string, Title:string, Enabled:bool, CanSpecifySecurityGroups:bool, EnabledSecurityGroups:dynamic, TenantSettingGroup:string, DelegatedToWorkspace:bool, DelegatedFrom:string, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table WorkspaceDelegatedSettingsHistory (WorkspaceId:guid, SettingName:string, Title:string, Enabled:bool, CanSpecifySecurityGroups:bool, EnabledSecurityGroups:dynamic, TenantSettingGroup:string, DelegatedFrom:string, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table WorkspaceDelegatedSettings (WorkspaceId:guid, SettingName:string, Title:string, Enabled:bool, CanSpecifySecurityGroups:bool, EnabledSecurityGroups:dynamic, TenantSettingGroup:string, DelegatedFrom:string, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table AppsHistory (AppName:string, AppId:guid, Description:string, PublishedBy:string, LastUpdate:datetime, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table Apps (AppName:string, AppId:guid, Description:string, PublishedBy:string, LastUpdate:datetime, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table JobEventsRaw (id:guid, datacontenttype:string, specversion:real, source:guid, ['time']:datetime, subject:string, dataschemaversion:real, type:string, data:dynamic) with (folder = "Platform/History/Events") 
.create-or-alter table JobEventsRaw ingestion json mapping 'JobEventsRaw_mapping'
```
[{"Properties":{"Path":"$['id']"},"column":"id","datatype":""},{"Properties":{"Path":"$['datacontenttype']"},"column":"datacontenttype","datatype":""},{"Properties":{"Path":"$['specversion']"},"column":"specversion","datatype":""},{"Properties":{"Path":"$['source']"},"column":"source","datatype":""},{"Properties":{"Path":"$['time']"},"column":"time","datatype":""},{"Properties":{"Path":"$['subject']"},"column":"subject","datatype":""},{"Properties":{"Path":"$['dataschemaversion']"},"column":"dataschemaversion","datatype":""},{"Properties":{"Path":"$['type']"},"column":"type","datatype":""},{"Properties":{"Path":"$['data']"},"column":"data","datatype":""}]
```
.create-merge table CapacityRegions (Continent:string, FabricRegion:string, Latitude:real, Longitude:real, Location:string) with (folder = "Platform/Auxiliar") 
.create-merge table SemanticModelContentTypes (ContentProviderType:string, MappedName:string, IsIncludedInOptimizationModule:bool, IsDefaultSemanticModel:bool) with (folder = "Platform/Auxiliar") 
.create-merge table CapacityEventsRaw (specversion:real, source:guid, ['time']:datetime, id:guid, subject:string, type:string, data:dynamic) with (folder = "Platform/History/Events") 
.create-or-alter table CapacityEventsRaw ingestion json mapping 'CapacityEventsRaw_mapping'
```
[{"Properties":{"Path":"$['specversion']"},"column":"specversion","datatype":""},{"Properties":{"Path":"$['source']"},"column":"source","datatype":""},{"Properties":{"Path":"$['time']"},"column":"time","datatype":""},{"Properties":{"Path":"$['id']"},"column":"id","datatype":""},{"Properties":{"Path":"$['subject']"},"column":"subject","datatype":""},{"Properties":{"Path":"$['type']"},"column":"type","datatype":""},{"Properties":{"Path":"$['data']"},"column":"data","datatype":""}]
```
.create-merge table CapacitySummary (id:guid, specversion:real, source:guid, ['time']:datetime, subject:string, type:string, baseCapacityUnits:long, capacityId:guid, capacityName:string, capacitySku:string, capacityUnitMs:real, timepointCapacityUnits:long, capacityUnitSecond:real, windowStartTime:datetime, windowEndTime:datetime, data:dynamic) with (folder = "Platform/Events") 
.create-merge table CapacityOperations (id:guid, specversion:real, source:guid, ['time']:datetime, subject:string, type:string, capacityId:guid, capacityName:string, capacitySku:string, capacityUnitMs:long, durationMs:long, isVirtualArtifactName:bool, isVirtualWorkspaceName:bool, itemId:guid, itemKind:string, itemName:string, operationId:string, operationName:string, operationStartTime:datetime, releaseType:string, status:string, throttlingDelayMs:long, utilizationType:string, windowStartTime:datetime, windowEndTime:datetime, workloadAutoscaleCapacityUnitsLimit:long, workspaceId:guid, workspaceName:string, workspaceDomainId:string, workspaceDomain:string, workspaceParentDomainId:string, workspaceParentDomain:string, data:dynamic) with (folder = "Platform/Events") 
.create-merge table RefreshablesRaw (['Workspace Id']:guid, ['Workspace Name']:string, ['Item Id']:guid, ['Item Name']:string, ['Item Kind']:string, ['Capacity Id']:guid, ['Capacity Name']:string, ['Capacity SKU']:string, ['Refresh Count']:int, ['Refresh Failures']:int, ['Average Duration']:decimal, ['Median Duration']:decimal, ['Refreshes Per Day']:int, ['Refresh Type']:string, ['Start Time']:string, ['End Time']:string, Status:string, ['Request Id']:guid, ['Service Exception Json']:string, ['Extended Status']:dynamic, ['Refresh Attempts']:dynamic, ['Refresh Schedule Days']:dynamic, ['Refresh Schedule Times']:dynamic, ['Refresh Schedule Enabled']:bool, ['Refresh Schedule Local Timezone Id']:string, ['Refresh Schedule Notify Option']:string, ['Configured By']:dynamic) with (folder = "Platform/History/Inventory") 
.create-merge table ItemRefreshes (['Request Id']:guid, IngestionTime:datetime, ['Workspace Id']:guid, ['Workspace Name']:string, ['Item Id']:guid, ['Item Name']:string, ['Item Kind']:string, ['Capacity Id']:guid, ['Capacity Name']:string, ['Capacity SKU']:string, ['Refresh Type']:string, ['Start Time']:datetime, ['End Time']:datetime, Status:string, ['Service Exception Json']:string, ['Extended Status']:dynamic, ['Refresh Attempts']:dynamic, Duration:timespan, DurationMs:real) with (folder = "Platform/Events") 
.create-merge table GitConnectionsHistory (['Workspace Id']:guid, ['Workspace Name']:string, ['Organization Name']:string, ['Owner Name']:string, ['Project Name']:string, ['Git Provider Type']:string, ['Repository Name']:string, ['Branch Name']:string, ['Directory Name']:string, scanTime:datetime) with (folder = "Platform/History/Inventory") 
.create-merge table GitConnections (['Workspace Id']:guid, ['Workspace Name']:string, ['Organization Name']:string, ['Owner Name']:string, ['Project Name']:string, ['Git Provider Type']:string, ['Repository Name']:string, ['Branch Name']:string, ['Directory Name']:string, scanTime:datetime) with (folder = "Platform/Inventory") 
.create-merge table CapacityState (id:guid, specversion:real, source:guid, ['time']:datetime, subject:string, type:string, capacityId:guid, capacityName:string, capacitySku:string, transitionTime:datetime, capacityState:string, stateChangeReason:string, data:dynamic) with (folder = "Platform/Events") 
.create-or-alter function with (folder = "Platform/UpdatePolicyFunctions", docstring = "Function to extract data from ActivityEventsRaw", skipvalidation = "true") parse_AcitivityEvents() {
    let columns=dynamic(["Id", "Workload", "RecordType", "RequestId", "RefreshEnforcementPolicy", "CreationTime", "Activity", "Operation", "OrganizationId", "UserId", "UserKey", "UserType"]);
    ActivityEventsRaw
    | extend
        Id=toguid(ActivityEvents.Id),
        CreationTime=todatetime(ActivityEvents.CreationTime)
    | join kind=leftanti ActivityEvents on CreationTime and Id
    | extend
        Workload=tostring(ActivityEvents.Workload),
        RecordType=toint(ActivityEvents.RecordType),
        RequestId=toguid(ActivityEvents.RequestId),
        RefreshEnforcementPolicy=toint(ActivityEvents.RefreshEnforcementPolicy),
        Activity=tostring(ActivityEvents.Activity),
        Operation=tostring(ActivityEvents.Operation),
        OrganizationId=toguid(ActivityEvents.OrganizationId),
        UserId=tostring(ActivityEvents.UserId),
        UserKey=tostring(ActivityEvents.UserKey),
        UserType=toint(ActivityEvents.UserType)
    | extend ActivityEvents=bag_remove_keys(ActivityEvents, columns)
    | project-rename details=ActivityEvents
    | project-reorder
        Id,
        Workload,
        RecordType,
        RequestId,
        RefreshEnforcementPolicy,
        CreationTime,
        Activity,
        Operation,
        OrganizationId,
        UserId,
        UserKey,
        UserType,
        details
 }
.create-or-alter function with (folder = "Platform/Inventory", skipvalidation = "true") SemanticModel() {
Items
| where itemType  == 'SemanticModel'
| extend targetStorageMode = tostring(details.targetStorageMode),contentProviderType=tostring(details.contentProviderType),configuredBy=tostring(details.configuredBy),createdDate=todatetime(details.createdDate)
| lookup SemanticModelDetails on itemId
| project-away workspaceId1,workspaceName1,itemName1,scanTime1,itemType1
| project-reorder workspaceId,workspaceName,itemType,itemId,itemName,createdDate,configuredBy,targetStorageMode,contentProviderType,tables,relationships,expressions,roles,upstreamDataflows
}
.create-or-alter function with (folder = "Platform/Inventory", skipvalidation = "true") Reports() {
Items
| where itemType == "Reports" and itemName !startswith "[App]"
| extend webUrl = strcat("https://app.powerbi.com/",workspaceId,"/reports/",itemId),
    embededUrl = strcat("https://app.powerbi.com/reportEmbed?reportId=",itemId),
    modifiedDateTime = todatetime(details.modifiedDateTime),
    createdDateTime = todatetime(details.createdDateTime)
| lookup ItemsLastView on $left.itemId == $right.ItemId
| project-rename lastViewDate = CreationTime
}
.create-or-alter function with (folder = "Platform/Inventory", skipvalidation = "true") Dataflows() {
Items
| where itemType == "Dataflows"
| extend generation = toint(details.generation),configuredBy=tostring(details.configuredBy),modifiedDateTime=todatetime(details.modifiedDateTime),modifiedBy=tostring(details.modifiedBy)
| project-reorder workspaceId,workspaceName,itemType,itemId,itemName,generation,configuredBy,modifiedDateTime,modifiedBy
}
.create-or-alter function with (folder = "Platform/Events", skipvalidation = "true") ItemsViews(daysToFilter:timespan=time(14.00:00:00)) {
    ActivityEvents
    | where CreationTime > ago(daysToFilter)
    | where Operation in ("ViewDashboard", "ViewDataflow", "ViewDatamart", "ViewReport", "ViewWarehouse","ViewArtifact","ReadArtifact")
    | project Id,CreationTime,Operation,UserId,WorkspaceId=toguid(details.WorkspaceId),WorkspaceName=tostring(details.WorkSpaceName),details,
        ItemType=tostring(case(
            Operation in ("ViewDashboard", "ViewReport"),details.ArtifactKind,
            Operation in ("ViewDataflow"),"Dataflow",
            Operation in ("ViewDatamart"),"Datamart",
            details.ObjectType
        )),
        ItemId=toguid(case(
            Operation in ("ViewDashboard", "ViewReport"),details.ArtifactId,
            Operation in ("ViewDataflow"),details.DataflowId,
            details.ObjectId
        )),
        ItemName=tostring(case(
            Operation in ("ViewDashboard", "ViewReport"),details.ArtifactName,
            Operation in ("ViewDataflow"),details.DataflowName,
            details.ObjectDisplayName
        ))
    | where isnotempty( ItemType)
}
.create-or-alter function with (folder = "Platform/Events", skipvalidation = "true") ItemsDeletion(daysToFilter:timespan=time(14.00:00:00)) {
    ActivityEvents
    | where CreationTime > ago(daysToFilter)
    | where Operation in ("DeleteDashboard", "DeleteDataflow", "DeleteDatamart", "DeleteReport", "DeleteWarehouse","DeleteArtifact")
    | project Id,CreationTime,Operation,UserId,workspaceId=toguid(details.WorkspaceId),workspaceName=tostring(details.WorkSpaceName),
        itemType=tostring(case(
            Operation in ("DeleteDashboard", "DeleteReport"),details.ArtifactKind,
            Operation in ("DeleteDataflow"),"Dataflow",
            Operation in ("DeleteDatamart"),"Datamart",
            details.ObjectType
        )),
        itemId=toguid(case(
            Operation in ("DeleteDashboard", "DeleteReport"),details.ArtifactId,
            Operation in ("DeleteDataflow"),iff(isempty(details.DataflowId),details.ObjectId,details.DataflowId),
            details.ObjectId
        )),
        itemName=tostring(case(
            Operation in ("DeleteDashboard", "DeleteReport"),details.ArtifactName,
            Operation in ("DeleteDataflow"),details.DataflowName,
            details.ObjectDisplayName
        ))
        | where iff(itemType=="Dataflow",isnotempty(itemName),true)
        | summarize arg_max(CreationTime,Id,Operation) by workspaceId,workspaceName,itemId,itemName, itemType,UserId
}
.create-or-alter function with (folder = "Platform/Events", skipvalidation = "true") ItemsCreation(daysToFilter:timespan=time(14.00:00:00)) {
     ActivityEvents
    | where Operation in ("CreateDataset", "CreateReport", "CreateDataflow", "CreateArtifact", "CreateDashboard", "CreateWarehouse")
    | where CreationTime > ago(daysToFilter)
    | project
        Id,
        CreationTime,
        Operation,
        UserId,
        WorkspaceId=toguid(details.WorkspaceId),
        WorkspaceName=tostring(details.WorkSpaceName),
        details,
        ItemType=tostring(
             case(
                 Operation in ("CreateDashboard", "CreateReport"),
                 details.ArtifactKind,
                 Operation in ("CreateDataset"),
                 "SemanticModel",
                 Operation in ("CreateDataflow"),
                 "Dataflow",
                 details.ObjectType
             )
         ),
        ItemId=toguid(
           case(
               Operation in ("CreateDashboard", "CreateReport", "CreateDataset"),
               details.ArtifactId,
               Operation in ("CreateDataflow"),
               iff(isempty(details.DataflowId), details.ObjectId, details.DataflowId),
               details.ObjectId
           )
       ),
        ItemName=tostring(
             case(
                 Operation in ("CreateDashboard", "CreateReport", "CreateDataset"),
                 details.ArtifactName,
                 Operation in ("CreateDataflow"),
                 details.DataflowName,
                 details.ObjectDisplayName
             )
         )
    | summarize arg_max(CreationTime, *) by ItemId
 }
.create-or-alter function with (folder = "Platform/Inventory", skipvalidation = "true") ExpandSemanticModelObjectExpressions(p_itemIds:string="") {
let v_itemIds = iff(isempty(p_itemIds), dynamic([]), split(p_itemIds, ","));
let Foreground =
SemanticModelDetails
| where array_length(tables) > 0
| where iff(array_length(v_itemIds) > 0, itemId in (p_itemIds), true)
| mv-expand smObjects = tables
| extend
    smObjectName = tostring(smObjects.name),
    smObjectStorageMode = coalesce(tostring(smObjects.storageMode), 'Missing')
| mv-expand with_itemindex=partition sources = smObjects.source
| extend smObjectExpression = tostring(sources.expression)
| extend
    smObjectExpressionClean =
    replace(@"(?:[^:]|^)//.*(\r?\n|$)", "", // remove multi-line comments
    replace(@"/\*[\s\S]*?\*/", "", smObjectExpression)) // remove double-slash comments
| extend smObjectType = case(
    smObjectExpression == smObjectName, 'DQtoAS',
    isempty(smObjectExpression), 'DQtoAS',
    smObjectExpression matches regex @"\b(IsParameterQuery)\b", 'MParameter',
    partition > 0, 'MQuery',
    smObjectExpression matches regex @"\b(let)\b", 'MQuery',
    smObjectExpression matches regex @"[a-z]\.[A-Z]" and
    not(smObjectExpression matches regex @"\b(?i)(calculatetable|generate|calendar|calendarauto|distinct|datatable|filter|return|union|nameof|summarize|summarizecolumns|selectcolumns|values|row|groupby|all)\b"), 'MQuery',
    smObjectStorageMode == 'DirectQuery', 'DQtoAS',
    'DAX' )
| project-away relationships, roles, upstreamDataflows, tables, expressions, smObjects, sources ;
let Background =
SemanticModelDetails
| where array_length(expressions) > 0
| where iff(array_length(v_itemIds) > 0, itemId in (p_itemIds), true)
| mv-expand smObjects = expressions
| extend
    smObjectName = tostring(smObjects.name),
    smObjectStorageMode = 'Background',
    partition = 0,
    smObjectExpression = tostring(smObjects.expression)
| extend
    smObjectExpressionClean =
    replace(@"(?:[^:]|^)//.*(\r?\n|$)", "", // remove multi-line comments
    replace(@"/\*[\s\S]*?\*/", "", smObjectExpression)) // remove double-slash comments
| extend smObjectType = case(
    smObjectName == 'ScorecardId', 'pbiGoals',
    smObjectExpression matches regex @"\b(IsParameterQuery)\b", 'MParameter',
    smObjectExpression matches regex @"\b(let)\b", 'MQuery',
    'MQuery' )
| project-away relationships, roles, upstreamDataflows, tables, expressions, smObjects ;
Foreground | union Background
| extend firstStepContents = case(
    smObjectType == 'MParameter', extract(@"^(.*?)\s+meta\b", 1, smObjectExpressionClean),
    extract(@"^(?:[^\n]*\n?){1,2}", 0, smObjectExpressionClean) matches regex @"=>\s", extract(@"^[^=]*=\s*([^,]*=>)", 1, smObjectExpressionClean),
    smObjectType == 'MQuery', extract(@"=\s*([^,]*)", 1, smObjectExpressionClean),
    ""
)
| extend dataAccessFunction = case(
    smObjectType !startswith "M", "Not M",
    smObjectType == "MParameter", strcat(extract(@'Type\s*=\s*"([^"]*)"', 1, smObjectExpressionClean), ' Parameter'),
    smObjectExpression matches regex @"\b(Snowflake\.Databases)\b", 'Snowflake',
    smObjectExpression matches regex @"\b(SapHana\.Database)\b", 'SAP HANA',
    smObjectExpression matches regex @"\b(SapBusinessWarehouse\.Cubes)\b", 'SAP BW',
    smObjectExpression matches regex @"\b(\.Dataflows)\b", 'Dataflows',
    smObjectExpression matches regex @"\b(Databricks\.)\b", 'Databricks',
    smObjectExpression matches regex @"\b(AzureStorage\.)\b", 'Azure Storage',
    smObjectExpression matches regex @"\b(AnalysisServices\.)\b", 'Analysis Services',
    smObjectExpression matches regex @"\b(Sql\.Database|Sql\.Databases)\b", 'SQL Server',
    smObjectExpression matches regex @"\b(GoogleAnalytics\.Accounts|GoogleBigQuery\.Database)\b", 'Google Analytics',
    smObjectExpression matches regex @"\b(Salesforce\.)\b", 'Salesforce',
    smObjectExpression matches regex @"\b(SharePoint\.)\b", 'SharePoint',
    smObjectExpression matches regex @"\b(TeamsAnalytics\.)\b", 'Teams Analytics',
    smObjectExpression matches regex @"\b(Excel\.Workbook)\b", 'Excel',
    smObjectExpression matches regex @"\b(Csv\.Document)\b", 'csv',
    smObjectExpression matches regex @"\b(Folder\.)\b", 'Folder',
    smObjectExpression matches regex @"\b(File\.Contents)\b", 'File',
    smObjectExpression matches regex @"\b(Web\.)\b", 'Web',
    smObjectExpression matches regex @"\b(Json\.Document\(Binary\.Decompress\(Binary\.FromText)\b", 'Entered Data',
    smObjectExpression matches regex @"\b(OData|OleDb|Odbc)\b", 'OData, ODBC or OLE DB',
    smObjectExpression matches regex @"\b(Oracle\.Database)\b", 'Oracle',
    smObjectExpression matches regex @"\b(Table\.Combine|Table\.NestedJoin)\b", 'Query reference',
    firstStepContents matches regex @"=>", 'Custom function',
    firstStepContents matches regex @"^[\s]*#"".*""[\s]*$", 'Query reference',  // Matches #"QueryName"
    firstStepContents matches regex @"^[\s]*"".*""[\s]*$", 'Text reference',  // Matches "text"
    firstStepContents !contains "." and firstStepContents !contains "(" and firstStepContents !contains "{", 'Query reference',  // No dots or parentheses
    'Other M Formula'
)}
.create-or-alter function with (folder = "Gateway/Parsers", skipvalidation = "true") parse_QueryStartReport_csv(T:(GatewayObjectId:guid,RequestId:guid,DataSource:dynamic,QueryTrackingId:guid,QueryExecutionStartTimeUTC:datetime,QueryType:string,QueryText:string,EvaluationContext:string)) {
      T
      | project GatewayObjectId,
            RequestId,
            DataSource=parse_json(DataSource),
            QueryTrackingId,
            QueryExecutionStartTimeUTC,
            OperationType=QueryType,
            QueryText = base64_decode_tostring(QueryText),
            Table = iff(isempty(extract("__AS_Query__ = (.+),",1,base64_decode_tostring(QueryText))),extract("<ccon>(.+)</ccon>",1,base64_decode_tostring(QueryText)),extract("__AS_Query__ = (.+),",1,base64_decode_tostring(QueryText))),
            EvaluationContext=parse_json(iff(isempty(parse_json(EvaluationContext)),'{"serviceTraceContexts":[{"serviceName":"Dataflow Gen1"}]}',EvaluationContext)),
            ServiceTraceContexts=parse_json(iff(isempty(parse_json(EvaluationContext)),'{"serviceTraceContexts":[{"serviceName":"Dataflow Gen1"}]}',EvaluationContext)).serviceTraceContexts
      | mv-expand ServiceTraceContexts
      | extend ServiceName=ServiceTraceContexts.serviceName
      | mv-expand ServiceTraceContexts.traceIds
      | evaluate bag_unpack(ServiceTraceContexts_traceIds) : (
            GatewayObjectId:guid,
            RequestId:guid,
            DataSource:dynamic,
            QueryTrackingId:guid,
            QueryExecutionStartTimeUTC:datetime,
            OperationType:string,
            QueryText:string,
            Table:string,
            EvaluationContext:dynamic,
            ServiceTraceContexts:dynamic,
            ServiceName:string,
            key:string,
            value:string
      )
      | evaluate pivot(key,take_any(value)) : (
            GatewayObjectId:guid,
            RequestId:guid,
            DataSource:dynamic,
            QueryTrackingId:guid,
            QueryExecutionStartTimeUTC:datetime,
            OperationType:string,
            QueryText:string,
            Table:string,
            EvaluationContext:dynamic,
            ServiceName:string,
            CurrentActivityId:guid,
            ["Session Id"]:guid,
            ["Host Context Type"]:string,
            ["Connection Ids"]:string,
            ["Dataflow Id"]:guid,
            ["Workspace Id"]:guid,
            DatasetId:guid,
            QueryType:string,
            RootActivityId:guid,
            SKU:string,
            WorkspaceId:guid
      )
      | project GatewayObjectId
            ,RequestId
            ,DataSource=parse_json((replace_strings(dynamic_to_json(DataSource),dynamic(['["','"]','}","{','\\"']),dynamic(['[',']','},{','"']))))
            ,QueryTrackingId
            ,QueryExecutionStartTimeUTC
            ,OperationType
            ,QueryText
            ,Table
            ,EvaluationContext
            ,ServiceName
            ,CurrentActivityId
            ,ItemId = iff(isempty(DatasetId),["Dataflow Id"],DatasetId)
            ,QueryType
            ,RootActivityId = iff(isempty(RootActivityId),["Session Id"],RootActivityId)
            ,SKU
            ,WorkspaceId = iff(isempty(WorkspaceId),['Workspace Id'],WorkspaceId)
            ,HostContextType=["Host Context Type"]
            ,ConnectionIds=["Connection Ids"]
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from QueryStartReport", skipvalidation = "true") parse_QueryStartReport() {
  ['GatewayReports-Raw']
    | where logType == "QueryStartReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      RequestId:guid,
      DataSource:dynamic,
      QueryTrackingId:guid,
      QueryExecutionStartTimeUTC:datetime,
      QueryType:string,
      QueryText:string,
      EvaluationContext:string
    )
    | invoke parse_QueryStartReport_csv()
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from QueryExecutionReport", skipvalidation = "true") parse_QueryExecutionReport() {
  ['GatewayReports-Raw']
    | where logType == "QueryExecutionReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      RequestId:guid,
      DataSource:dynamic,
      QueryTrackingId:guid,
      QueryExecutionEndTimeUTC:datetime,
      ['QueryExecutionDuration(ms)']:long,
      QueryType:string,
      ['DataReadingAndSerializationDuration(ms)']:long,
      ['SpoolingDiskWritingDuration(ms)']:long,
      ['SpoolingDiskReadingDuration(ms)']:long,
      ['SpoolingTotalDataSize(byte)']:long,
      DataProcessingEndTimeUTC:datetime,
      ['DataProcessingDuration(ms)']:long,
      Success:string,
      ErrorMessage:string
      )
  | project GatewayObjectId,
    RequestId,
    DataSource=parse_json((replace_strings(dynamic_to_json(DataSource),dynamic(['["','"]','\\"']),dynamic(['[',']','"'])))),
    QueryTrackingId,
    QueryExecutionEndTimeUTC,
    ['QueryExecutionDuration(ms)'],
    QueryType,
    ['DataReadingAndSerializationDuration(ms)'],
    ['SpoolingDiskWritingDuration(ms)'],
    ['SpoolingDiskReadingDuration(ms)'],
    ['SpoolingTotalDataSize(byte)'],
    DataProcessingEndTimeUTC,
    ['DataProcessingDuration(ms)'],
    Success,
    ErrorMessage
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from OpenConnectionReport", skipvalidation = "true") parse_OpenConnectionReport() {
  ['GatewayReports-Raw']
    | where logType == "OpenConnectionReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      DataSource:dynamic,
      OpenConnectionStartTimeUTC:datetime,
      OpenConnectionTrackingId:guid,
      ProviderName:string,
      RequestId:guid,
      ["OpenConnectionDuration(ms)"]:long,
      Success:string,
      ErrorMessage:string
      )
  | project GatewayObjectId,
    RequestId,
    DataSource=parse_json((replace_strings(dynamic_to_json(DataSource),dynamic(['["','"]','\\"']),dynamic(['[',']','"'])))),
    OpenConnectionStartTimeUTC,
    OpenConnectionTrackingId,
    ProviderName,
    ["OpenConnectionDuration(ms)"],
    Success,
    ErrorMessage
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from QueryExecutionAggregationReport", skipvalidation = "true") parse_QueryExecutionAggregationReport() {
  ['GatewayReports-Raw']
    | where logType == "QueryExecutionAggregationReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      AggregationStartTimeUTC:datetime,
      AggregationEndTimeUTC:datetime,
      DataSource:dynamic,
      Success:string,
      AverageQueryExecutionDuration_ms_:real,
      MaxQueryExecutionDuration_ms_:long,
      MinQueryExecutionDuration_ms_:long,
      QueryType:string,
      AverageDataProcessingDuration_ms_:real,
      MaxDataProcessingDuration_ms_:long,
      MinDataProcessingDuration_ms_:long,
      Count:long
      )
  | project GatewayObjectId,
      AggregationStartTimeUTC,
      AggregationEndTimeUTC,
      DataSource=parse_json((replace_strings(dynamic_to_json(DataSource),dynamic(['["','"]','\\"']),dynamic(['[',']','"'])))),
      Success,
      AverageQueryExecutionDuration_ms_,
      MaxQueryExecutionDuration_ms_,
      MinQueryExecutionDuration_ms_,
      QueryType,
      AverageDataProcessingDuration_ms_,
      MaxDataProcessingDuration_ms_,
      MinDataProcessingDuration_ms_,
      Count
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from QueryStreamingReport", skipvalidation = "true") parse_QueryStreamingReport() {
  ['GatewayReports-Raw']
    | where logType == "QueryStreamingReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      RequestId:guid,
      DataSource:dynamic,
      QueryTrackingId:guid,
      StreamingStartTimeUTC:datetime,
      SpoolingDiskReadingDuration_ms_:long,
      StreamingDuration_ms_:long,
      Success:string,
      ErrorMessage:string
    )
  | project GatewayObjectId,
      RequestId,
      DataSource=parse_json((replace_strings(dynamic_to_json(DataSource),dynamic(['["','"]','\\"']),dynamic(['[',']','"'])))),
      QueryTrackingId,
      StreamingStartTimeUTC,
      SpoolingDiskReadingDuration_ms_,
      StreamingDuration_ms_,
      Success,
      ErrorMessage
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from MashupEvaluationReport", skipvalidation = "true") parse_MashupEvaluationReport() {
  ['GatewayReports-Raw']
    | where logType == "MashupEvaluationReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      QueryTrackingId:guid,
      ConnectionId:guid,
      DataSourceKinds:string,
      DataSourcePaths:string,
      EndTimeUTC:datetime,
      ['AverageCommit byte']:real ,
      AverageIODataBytesPerSecond:real,
      AveragePercentProcessorTime:real,
      ['AverageWorkingSet byte']:real,
      ['MaxCommit byte']:long,
      MaxIODataBytesPerSecond:long,
      MaxPercentProcessorTime:real,
      ['MaxWorkingSet byte']:long,
      TotalBytes:long,
      TotalProcessorTime:timespan,
      TotalRows:real
    )
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from SystemCounterAggregationReport", skipvalidation = "true") parse_SystemCounterAggregationReport() {
  ['GatewayReports-Raw']
    | where logType == "SystemCounterAggregationReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid ,
      AggregationStartTimeUTC:datetime ,
      AggregationEndTimeUTC:datetime,
      CounterName:string,
      Max:real,
      Min:real,
      Average:real
    )
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from MashupEvaluationReport", skipvalidation = "true") parse_ConcurrentOperationAggregationReport() {
  ['GatewayReports-Raw']
    | where logType == "ConcurrentOperationAggregationReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
      GatewayObjectId:guid,
      AggregationStartTimeUTC:datetime ,
      AggregationEndTimeUTC:datetime,
      CounterName:string,
      Max:real,
      Min:real,
      Average:real
    )
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from GatewayNodeInfo", skipvalidation = "true") parse_GatewayNodeInfoRaw() {
  ['GatewayReports-Raw']
    | where logType == "GatewayNodeInfo"
    | project log,logDate
    | mv-expand log
    | evaluate bag_unpack(log) : (
      clusterId:guid,
      clusterName:string,
      nodeId:guid,
      machine:string, 
      cloudDatasourceRefresh:bool, 
      contactInformation:string, 
      customConnectors:bool,
      status:string,
      type:string,
      version:string,
      versionStatus:string,
      osName:string,
      osVersion:string,
      cores:long,
      logicalCores:long,
      memoryGb:real,
      logDate:datetime 
    )
}
.create-or-alter function with (folder = "Gateway/UpdatePolicyFunctions", docstring = "Function to extract data from CopyExecutionReport", skipvalidation = "true") parse_CopyExecutionReport() {
  ['GatewayReports-Raw']
    | where logType == "CopyExecutionReport"
    | project log
    | mv-expand log
    | evaluate bag_unpack(log) : (
        GatewayObjectId:guid,
        ActivityId:guid, 
        CopyExecutionStartTimeUTC:datetime, 
        CompletionStatus:string, 
        ['CopyExecutionDuration(ms)']:decimal,    
        ['CopyWorkerCPUUtilization(%)']:decimal, 
        ['CopyWorkerMemoryUsage(byte)']:decimal
    )
    | project-rename ['CopyExecutionDuration_ms']=['CopyExecutionDuration(ms)'], 
    ['CopyWorkerCPUUtilizationPercentage']=['CopyWorkerCPUUtilization(%)'],
    ['CopyWorkerMemoryUsage_byte']=['CopyWorkerMemoryUsage(byte)']
}
.create-or-alter function with (folder = "Gateway/Functions", docstring = "Function to merge the GatewayNodeInfo and Heartbeat", skipvalidation = "true") GatewayNodeStatusWithInfo() {
    GatewayNodeInfo
    | join kind=fullouter GatewayNodeStatus on nodeId
    | extend Responding=tobool(iff(datetime_diff('minute',now(),lastStatusDate)>1 or isempty(lastStatusDate),false,true))
    | project nodeId,logDate,clusterId,clusterName,machine,cloudDatasourceRefresh,contactInformation,customConnectors,status,type,version,versionStatus,osName,osVersion,cores,logicalCores,memoryGb,lastStatusDate,Responding
}
.create-or-alter function with (folder = "Gateway/Functions", docstring = "Function to get Query Connections", skipvalidation = "true") QueryConnections(DateSearch:datetime, DaysBack:int, AllGateways:bool, Gateways:dynamic, AllClusters:bool, Clusters:dynamic) {
     let TimeFrom = datetime_add('day', -DaysBack, DateSearch);
     let TimeToStart = datetime_add('hour', 24, DateSearch);
     let TimeToExecute = datetime_add('hour', 30, DateSearch);
     let GatewaysToSeach = GatewayNodeInfo | where AllGateways or machine in(Gateways) | where AllClusters or clusterName in(Clusters) | project nodeId;
     let QueryExecution = QueryExecutionReport
        | where QueryExecutionEndTimeUTC >= TimeFrom and QueryExecutionEndTimeUTC <= TimeToExecute
        | where GatewayObjectId in(GatewaysToSeach);
     let QueryStart = QueryStartReport
        | where QueryExecutionStartTimeUTC >= TimeFrom and QueryExecutionStartTimeUTC <= TimeToStart
        | where GatewayObjectId in(GatewaysToSeach);
     QueryStart
    | mv-expand todynamic(DataSource)
    | extend DataSource=DataSource.kind, Path=DataSource.path
    | project QueryTrackingId, DataSource=tostring(DataSource), Path=tostring(Path)
 }
.create-or-alter function with (folder = "Gateway/Functions", docstring = "Function to merge the Query Start and Execution", skipvalidation = "true") QueryExecutionUnified(DateSearch:datetime, DaysBack:int, AllGateways:bool, Gateways:dynamic, AllClusters:bool, Clusters:dynamic) {
     let TimeFrom = datetime_add('day', -DaysBack, DateSearch);
     let TimeToStart = datetime_add('hour', 24, DateSearch);
     let TimeToExecute = datetime_add('hour', 36, DateSearch);
     let GatewaysToSeach = GatewayNodeInfo | where AllGateways or machine in(Gateways) | where AllClusters or clusterName in(Clusters) | project nodeId;
     let QueryExecution = QueryExecutionReport
        | where QueryExecutionEndTimeUTC >= TimeFrom and QueryExecutionEndTimeUTC <= TimeToExecute
        | where GatewayObjectId in(GatewaysToSeach);
     let QueryStart = QueryStartReport
        | where QueryExecutionStartTimeUTC >= TimeFrom and QueryExecutionStartTimeUTC <= TimeToStart
        | where GatewayObjectId in(GatewaysToSeach);
     QueryStart
    | join kind=leftouter QueryExecution
        on
        $left.GatewayObjectId == $right.GatewayObjectId,
        $left.RequestId == $right.RequestId,
        $left.QueryTrackingId == $right.QueryTrackingId
    | lookup GatewayNodeInfo on $left.GatewayObjectId == $right.nodeId
    | project
        RootActivityId,
        GatewayObjectId, 
        ClusterName=clusterName,
        NodeName=machine,
        WorkspaceId, 
        ItemId, 
        QueryExecutionStartTimeUTC, 
        QueryExecutionEndTimeUTC,  
        QueryExecutionDuration_ms_,
        DataProcessingEndTimeUTC,
        DataProcessingDuration_ms_,
        RequestId, 
        QueryTrackingId,
        CurrentActivityId,
        Success,
        QueryText,
        Table,
        OperationType,
        QueryType,    
        DataSource,
        ServiceName,
        SKU,
        DataReadingAndSerializationDuration_ms_,
        SpoolingDiskWritingDuration_ms_,
        SpoolingDiskReadingDuration_ms_,
        SpoolingTotalDataSize_byte_,
        ErrorMessage,
        HostContextType,
        ConnectionIds
    | order by
        RootActivityId,
        GatewayObjectId,
        WorkspaceId,
        ItemId,
        QueryExecutionStartTimeUTC desc,
        RequestId,
        QueryTrackingId
 }
.create-or-alter function with (folder = "Gateway/Functions", docstring = "Function to get SystemCounters", skipvalidation = "true") SystemCounters(DateSearch:datetime, DaysBack:int, AllGateways:bool, Gateways:dynamic, AllClusters:bool, Clusters:dynamic) {
     let TimeFrom = datetime_add('day', -DaysBack, DateSearch);
     let TimeTo = datetime_add('hour', 24, DateSearch);
     let GatewaysToSeach = GatewayNodeInfo
        | where AllGateways or machine in(Gateways)
        | where AllClusters or clusterName in(Clusters)
        | project nodeId;
     let SystemCounter = SystemCounterAggregationReport
        | where AggregationEndTimeUTC >= TimeFrom and AggregationEndTimeUTC <= TimeTo
        | where GatewayObjectId in(GatewaysToSeach);
     SystemCounter
    | lookup GatewayNodeInfo on $left.GatewayObjectId == $right.nodeId
    | project 
        ClusterId=clusterId,
        ClusterName=clusterName,
        NodeId=GatewayObjectId, 
        NodeName=machine,
        AggregationEndTimeUTC,
        CounterName,
        Max,
        Min,
        Average
 }
.create-or-alter function with (folder = "Platform/UpdatePolicyFunctions", skipvalidation = "true") parse_CapacityEventsSummary() {
     CapacityEventsRaw
    | where ["type"] == "Microsoft.Fabric.Capacity.Summary"
    | extend
        baseCapacityUnits=tolong(data.baseCapacityUnits),
        capacityId=toguid(data.capacityId),
        capacityName=tostring(data.capacityName),
        capacitySku=tostring(data.capacitySku),
        capacityUnitMs=toreal(data.capacityUnitMs),
        windowEndTime=todatetime(data.windowEndTime),
        windowStartTime=todatetime(data.windowStartTime)
    | extend
        timepointCapacityUnits = baseCapacityUnits * 30,
        capacityUnitSecond=capacityUnitMs / 1000.0
    | project
        id,
        specversion,
        source,
        ['time'],
        subject,
        type,
        baseCapacityUnits,
        capacityId,
        capacityName,
        capacitySku,
        capacityUnitMs,
        timepointCapacityUnits,
        capacityUnitSecond,
        windowStartTime,
        windowEndTime,
        data
 }
.create-or-alter function with (folder = "Platform/UpdatePolicyFunctions", skipvalidation = "true") parse_CapacityEventsOperation() {
CapacityEventsRaw
| where ["type"] == "Microsoft.Fabric.Capacity.Operation"
| extend
    capacityId=toguid(data.capacityId),
    capacityName=tostring(data.capacityName),
    capacitySku=tostring(data.capacitySku),
    capacityUnitMs=tolong(data.capacityUnitMs),
    durationMs=tolong(data.durationMs),
    isVirtualArtifactName=tobool(data.isVirtualArtifactName),
    isVirtualWorkspaceName=tobool(data.isVirtualWorkspaceName),
    itemId=toguid(data.itemId),
    itemKind=tostring(data.itemKind),
    itemName=tostring(data.itemName),
    operationId= iff(isempty(data.operationId), tostring(new_guid()), tostring(data.operationId)),
    operationName=tostring(data.operationName),
    operationStartTime=todatetime(data.operationStartTime),
    releaseType=tostring(data.releaseType),
    status=tostring(data.status),
    throttlingDelayMs=tolong(data.throttlingDelayMs),
    utilizationType=tostring(data.utilizationType),
    windowEndTime=todatetime(data.windowEndTime),
    windowStartTime=todatetime(data.windowStartTime),
    workloadAutoscaleCapacityUnitsLimit=tolong(data.workloadAutoscaleCapacityUnitsLimit),
    workspaceDomain=tostring(data.workspaceDomain),
    workspaceDomainId=tostring(data.workspaceDomainId),
    workspaceId=toguid(data.workspaceId),
    workspaceName=tostring(data.workspaceName),
    workspaceParentDomain=tostring(data.workspaceParentDomain),
    workspaceParentDomainId=tostring(data.workspaceParentDomainId)
| project
    id,
    specversion,
    source,
    ['time'],
    subject,
    type,
    capacityId,
    capacityName,
    capacitySku,
    capacityUnitMs,
    durationMs,
    isVirtualArtifactName,
    isVirtualWorkspaceName,
    itemId,
    itemKind,
    itemName,
    operationId,
    operationName,
    operationStartTime,
    releaseType,
    status,
    throttlingDelayMs,
    utilizationType,
    windowStartTime,
    windowEndTime,
    workloadAutoscaleCapacityUnitsLimit,
    workspaceId,
    workspaceName,
    workspaceDomainId,
    workspaceDomain,        
    workspaceParentDomainId,
    workspaceParentDomain,
    data
}
.create-or-alter function with (folder = "Platform/UpdatePolicyFunctions", skipvalidation = "true") parse_ItemRefreshes() {
RefreshablesRaw
| where ['Request Id'] != "None" and isnotempty(['Request Id'])
| where Status != "Unknown"
| extend IngestionTime=ingestion_time()
| summarize arg_max(IngestionTime, ['Workspace Id'], ['Workspace Name'], ['Item Id'], ['Item Name'], ['Item Kind'], ['Capacity Id'], ['Capacity Name'],['Capacity SKU'], ['Refresh Type'], ['Start Time']=todatetime(['Start Time']), ['End Time']=todatetime(['End Time']), Status, ['Service Exception Json'], ['Extended Status'], ['Refresh Attempts']) by ['Request Id']
| extend Duration=totimespan(['End Time'] - ['Start Time'])
| extend DurationMs=round(tolong(Duration)/10000,0)
| join kind=leftanti ItemRefreshes on ['Start Time'] and ['Request Id']
}
.create-or-alter function with (folder = "Platform/UpdatePolicyFunctions", skipvalidation = "true") parse_CapacityEventsState() {
CapacityEventsRaw
| where ["type"] == "Microsoft.Fabric.Capacity.State"
| extend
    capacityId=toguid(data.capacityId),
    capacityName=tostring(data.capacityName),
    capacitySku=tostring(data.capacitySku),
    transitionTime=todatetime(data.transitionTime),
    capacityState=tostring(data.capacityState),
    stateChangeReason=tostring(data.stateChangeReason)
| project
    id,
    specversion,
    source,
    ['time'],
    subject,
    type,
    capacityId,
    capacityName,
    capacitySku,
    transitionTime,
    capacityState,
    stateChangeReason,
    data
}
.create-or-alter materialized-view with (Folder = "Gateway/Information")  GatewayNodeInfo on table GatewayNodeInfoRaw { GatewayNodeInfoRaw | summarize arg_max(logDate, clusterId,clusterName,machine,cloudDatasourceRefresh,contactInformation,customConnectors,status,type,version,versionStatus,osName,osVersion,cores,logicalCores,memoryGb) by nodeId }
.create-or-alter materialized-view with (Folder = "Gateway/Information")  GatewayNodeStatus on table GatewaysHeartbeat { GatewaysHeartbeat | project-rename nodeId = GatewayId, lastStatusDate = ServerTimestampUTC | summarize arg_max(lastStatusDate,FileVersion,Responding) by nodeId }
.create-or-alter materialized-view with (Folder = "Platform/Events")  ItemsLastView on table ActivityEvents { ItemsViews()
    | summarize arg_max(CreationTime,Id,UserId) by ItemId }
.create-or-alter materialized-view with (Folder = "Platform/Events", DimensionTables = Items)  ActivitiesByItemsUsersDay on table ActivityEvents { ActivityEvents
| project Id,CreationTime,Operation, UserId=tolower(UserId),['Year-Month']=format_datetime(CreationTime,"yyyy-MM"),
    ItemId=toguid(case(
        isnotempty(details.ArtifactId), (details.ArtifactId),
        isnotempty(details.DataflowId), (details.DataflowId),
        (details.ObjectId)
    ))
| where isnotempty(ItemId)
| lookup  (Items | project-away details,scanTime) on  $left.ItemId == $right.itemId
| where isnotempty(itemName)
| summarize Events=count() by ['Year-Month'], bin(CreationTime,1d), workspaceId, workspaceName, ItemId,itemName,itemType, UserId, Operation }
.create-or-alter materialized-view with (Folder = "Platform/Events")  ActivitiesByWorkspaceUserDay on table ActivityEvents { ActivityEvents
| extend ['Year-Month'] = format_datetime(CreationTime,"yyyy-MM"), workspaceId = toguid(details.WorkspaceId), UserId=tolower(UserId)
| summarize Events=count() by ['Year-Month'], Operation, CreationDay=bin(CreationTime,1d), workspaceId,UserId }
.create-or-alter materialized-view with (Folder = "Platform/Inventory")  Refreshables on table RefreshablesRaw { RefreshablesRaw
| project-away ['Refresh Type'], ['Start Time'], ['End Time'], Status, ['Request Id'],['Service Exception Json'], ['Extended Status'], ['Refresh Attempts']
| extend IngestionTime = ingestion_time()
| summarize arg_max(IngestionTime,['Workspace Name'],['Item Name'],['Item Kind'],['Refresh Count'],['Refresh Failures'],['Average Duration'],['Median Duration'],['Refreshes Per Day'],['Refresh Schedule Days'],['Refresh Schedule Times'],['Refresh Schedule Enabled'],['Refresh Schedule Notify Option'],['Configured By']) by ['Workspace Id'], ['Item Id'] }
.alter table ActivityEventsRaw policy retention @'{"SoftDeletePeriod":"00:00:00","Recoverability":"Disabled"}'
.alter table ActivityEventsRaw policy caching hotdata = time(00:00:00) hotindex = time(00:00:00)
.alter table ActivityEventsRaw policy streamingingestion "{\"IsEnabled\":false,\"HintAllocatedRate\":null,\"NumberOfRowStores\":null,\"SealIntervalLimit\":null,\"SealThresholdBytes\":null,\"UsageTags\":[],\"IsMaintenanceActive\":false}"
.alter table ActivityEvents policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table ActivityEvents policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table ActivityEvents policy update "[{\"IsEnabled\":true,\"Source\":\"ActivityEventsRaw\",\"Query\":\"parse_AcitivityEvents()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table ActivityEvents policy streamingingestion "{\"IsEnabled\":false,\"HintAllocatedRate\":null,\"NumberOfRowStores\":null,\"SealIntervalLimit\":null,\"SealThresholdBytes\":null,\"UsageTags\":[],\"IsMaintenanceActive\":false}"
.alter table DatasourceInstancesHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table DatasourceInstancesHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table DatasourceInstancesHistory policy streamingingestion "{\"IsEnabled\":false,\"HintAllocatedRate\":null,\"NumberOfRowStores\":null,\"SealIntervalLimit\":null,\"SealThresholdBytes\":null,\"UsageTags\":[],\"IsMaintenanceActive\":false}"
.alter table TenantSettingsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table TenantSettingsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table CapacitiesHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table CapacitiesHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table DomainsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table DomainsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table WorkspacesHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table WorkspacesUsersHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table ItemsUsersHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table ItemsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table CapacityDelegatedSettingsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table CapacityDelegatedSettingsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table GatewaysHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table GatewaysHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table GatewayMembersHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table GatewayMembersHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table ConnectionsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table ConnectionsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table GatewaysHeartbeat policy retention @'{"SoftDeletePeriod":"7.00:00:00","Recoverability":"Disabled"}'
.alter table GatewaysHeartbeat policy caching hotdata = time(1.00:00:00) hotindex = time(1.00:00:00)
.alter table GatewaysHeartbeat policy streamingingestion "{\"IsEnabled\":true,\"HintAllocatedRate\":null,\"NumberOfRowStores\":null,\"SealIntervalLimit\":null,\"SealThresholdBytes\":null,\"UsageTags\":[],\"IsMaintenanceActive\":false}"
.alter table ['GatewayReports-Raw'] policy retention @'{"SoftDeletePeriod":"1.00:00:00","Recoverability":"Disabled"}'
.alter table ['GatewayReports-Raw'] policy caching hotdata = time(1.00:00:00) hotindex = time(1.00:00:00)
.alter table ['GatewayReports-Raw'] policy streamingingestion "{\"IsEnabled\":true,\"HintAllocatedRate\":null,\"NumberOfRowStores\":null,\"SealIntervalLimit\":null,\"SealThresholdBytes\":null,\"UsageTags\":[],\"IsMaintenanceActive\":false}"
.alter table SystemCounterAggregationReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table SystemCounterAggregationReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table SystemCounterAggregationReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_SystemCounterAggregationReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table QueryStartReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table QueryStartReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table QueryStartReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_QueryStartReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table QueryExecutionReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table QueryExecutionReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table QueryExecutionReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_QueryExecutionReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table OpenConnectionReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table OpenConnectionReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table OpenConnectionReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_OpenConnectionReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table QueryExecutionAggregationReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table QueryExecutionAggregationReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table QueryExecutionAggregationReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_QueryExecutionAggregationReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table QueryStreamingReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table QueryStreamingReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table QueryStreamingReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_QueryStreamingReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table MashupEvaluationReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table MashupEvaluationReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table MashupEvaluationReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_MashupEvaluationReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table ConcurrentOperationAggregationReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table ConcurrentOperationAggregationReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table ConcurrentOperationAggregationReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_ConcurrentOperationAggregationReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table GatewayNodeInfoRaw policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table GatewayNodeInfoRaw policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table GatewayNodeInfoRaw policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_GatewayNodeInfoRaw()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table CopyExecutionReport policy retention @'{"SoftDeletePeriod":"3650.00:00:00","Recoverability":"Enabled"}'
.alter table CopyExecutionReport policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table CopyExecutionReport policy update "[{\"IsEnabled\":true,\"Source\":\"GatewayReports-Raw\",\"Query\":\"parse_CopyExecutionReport()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table SemanticModelDetailsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter column SemanticModelDetailsHistory.['tables'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetailsHistory.['relationships'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetailsHistory.['expressions'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetailsHistory.['roles'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetailsHistory.['upstreamDataflows'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetails.['tables'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetails.['relationships'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetails.['expressions'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetails.['roles'] policy encoding type = 'BigObject32'
.alter column SemanticModelDetails.['upstreamDataflows'] policy encoding type = 'BigObject32'
.alter table DomainDelegatedSettingsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table DomainDelegatedSettingsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table WorkspaceDelegatedSettingsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table WorkspaceDelegatedSettingsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table AppsHistory policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table AppsHistory policy caching hotdata = time(730.00:00:00) hotindex = time(730.00:00:00)
.alter table CapacityEventsRaw policy retention @'{"SoftDeletePeriod":"00:00:00","Recoverability":"Disabled"}'
.alter table CapacitySummary policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table CapacitySummary policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table CapacitySummary policy update "[{\"IsEnabled\":true,\"Source\":\"CapacityEventsRaw\",\"Query\":\"parse_CapacityEventsSummary()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table CapacityOperations policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table CapacityOperations policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table CapacityOperations policy update "[{\"IsEnabled\":true,\"Source\":\"CapacityEventsRaw\",\"Query\":\"parse_CapacityEventsOperation()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter column CapacityOperations.['operationStartTime'] policy encoding type = 'EmbeddedPresenceLZ4'
.alter table RefreshablesRaw policy retention @'{"SoftDeletePeriod":"00:00:01","Recoverability":"Disabled"}'
.alter table RefreshablesRaw policy caching hotdata = time(00:01:00) hotindex = time(00:01:00)
.alter table RefreshablesRaw policy streamingingestion "{\"IsEnabled\":false,\"HintAllocatedRate\":null,\"NumberOfRowStores\":null,\"SealIntervalLimit\":null,\"SealThresholdBytes\":null,\"UsageTags\":[],\"IsMaintenanceActive\":false}"
.alter column RefreshablesRaw.['Workspace Id'] policy encoding type = 'Null'
.alter column RefreshablesRaw.['Item Id'] policy encoding type = 'Null'
.alter column RefreshablesRaw.['Capacity Id'] policy encoding type = 'Null'
.alter column RefreshablesRaw.['Request Id'] policy encoding type = 'Null'
.alter table ItemRefreshes policy retention @'{"SoftDeletePeriod":"750.00:00:00","Recoverability":"Disabled"}'
.alter table ItemRefreshes policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table ItemRefreshes policy update "[{\"IsEnabled\":true,\"Source\":\"RefreshablesRaw\",\"Query\":\"parse_ItemRefreshes()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter column ItemRefreshes.['Request Id'] policy encoding type = 'Null'
.alter column ItemRefreshes.['Workspace Id'] policy encoding type = 'Null'
.alter column ItemRefreshes.['Item Id'] policy encoding type = 'Null'
.alter column ItemRefreshes.['Capacity Id'] policy encoding type = 'Null'
.alter table GitConnectionsHistory policy retention @'{"SoftDeletePeriod":"750.00:00:00","Recoverability":"Disabled"}'
.alter table CapacityState policy retention @'{"SoftDeletePeriod":"730.00:00:00","Recoverability":"Disabled"}'
.alter table CapacityState policy caching hotdata = time(90.00:00:00) hotindex = time(90.00:00:00)
.alter table CapacityState policy update "[{\"IsEnabled\":true,\"Source\":\"CapacityEventsRaw\",\"Query\":\"parse_CapacityEventsState()\",\"IsTransactional\":true,\"PropagateIngestionProperties\":false,\"ManagedIdentity\":null}]"
.alter table Workspaces policy merge ```
{
  "RowCountUpperBoundForMerge": 16000000,
  "OriginalSizeMBUpperBoundForMerge": 30000,
  "MaxExtentsToMerge": 100,
  "MaxRangeInHours": 8760,
  "AllowRebuild": true,
  "AllowMerge": true,
  "Lookback": {
    "Kind": "All",
    "CustomPeriod": null
  },
  "Origin": "Default"
}```
.alter table WorkspacesUsers policy merge ```
{
  "RowCountUpperBoundForMerge": 16000000,
  "OriginalSizeMBUpperBoundForMerge": 30000,
  "MaxExtentsToMerge": 100,
  "MaxRangeInHours": 8760,
  "AllowRebuild": true,
  "AllowMerge": true,
  "Lookback": {
    "Kind": "All",
    "CustomPeriod": null
  },
  "Origin": "Default"
}```
.alter table Items policy merge ```
{
  "RowCountUpperBoundForMerge": 16000000,
  "OriginalSizeMBUpperBoundForMerge": 30000,
  "MaxExtentsToMerge": 100,
  "MaxRangeInHours": 8760,
  "AllowRebuild": true,
  "AllowMerge": true,
  "Lookback": {
    "Kind": "All",
    "CustomPeriod": null
  },
  "Origin": "Default"
}```
.alter table ItemsUsers policy merge ```
{
  "RowCountUpperBoundForMerge": 16000000,
  "OriginalSizeMBUpperBoundForMerge": 30000,
  "MaxExtentsToMerge": 100,
  "MaxRangeInHours": 8760,
  "AllowRebuild": true,
  "AllowMerge": true,
  "Lookback": {
    "Kind": "All",
    "CustomPeriod": null
  },
  "Origin": "Default"
}```
.alter table SemanticModelDetails policy merge ```
{
  "RowCountUpperBoundForMerge": 16000000,
  "OriginalSizeMBUpperBoundForMerge": 30000,
  "MaxExtentsToMerge": 100,
  "MaxRangeInHours": 8760,
  "AllowRebuild": true,
  "AllowMerge": true,
  "Lookback": {
    "Kind": "All",
    "CustomPeriod": null
  },
  "Origin": "Default"
}```
.alter table DatasourceInstance policy merge ```
{
  "RowCountUpperBoundForMerge": 16000000,
  "OriginalSizeMBUpperBoundForMerge": 30000,
  "MaxExtentsToMerge": 100,
  "MaxRangeInHours": 8760,
  "AllowRebuild": true,
  "AllowMerge": true,
  "Lookback": {
    "Kind": "All",
    "CustomPeriod": null
  },
  "Origin": "Default"
}```
